<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[Google File System]]></title>
      <url>%2F2017%2F01%2F28%2Fgoogle-file-system%2F</url>
      <content type="text"><![CDATA[转自http://blog.csdn.net/xuleicsu/article/details/526386 GFS是一个可扩展的分布式文件系统，用于大型的、分布式的、对大量数据进行访问的应用。它运行于廉价的普通硬件上，但可以提供容错功能。它可以给大量的用户提供总体性能较高的服务。 设计概览设计想法GFS与过去的分布式文件系统有很多相同的目标，但GFS的设计受到了当前及预期的应用方面的工作量及技术环境的驱动，这反映了它与早期的文件系统明显不同的设想。这就需要对传统的选择进行重新检验并进行完全不同的设计观点的探索。 GFS与以往的文件系统的不同的观点如下： 部件错误不再被当作异常，而是将其作为常见的情况加以处理。因为文件系统由成百上千个用于存储的机器构成，而这些机器是由廉价的普通部件组成并被大量的客户机访问。部件的数量和质量使得一些机器随时都有可能无法工作并且有一部分还可能无法恢复。所以实时地监控、错误检测、容错、自动恢复对系统来说必不可少。 按照传统的标准，文件都非常大。长度达几个GB的文件是很平常的。每个文件通常包含很多应用对象。当经常要处理快速增长的、包含数以万计的对象、长度达TB的数据集时，我们很难管理成千上万的KB规模的文件块，即使底层文件系统提供支持。因此，设计中操作的参数、块的大小必须要重新考虑。对大型的文件的管理一定要能做到高效，对小型的文件也必须支持，但不必优化。 大部分文件的更新是通过添加新数据完成的，而不是改变已存在的数据。在一个文件中随机的操作在实践中几乎不存在。一旦写完，文件就只可读，很多数据都有这些特性。一些数据可能组成一个大仓库以供数据分析程序扫描。有些是运行中的程序连续产生的数据流。有些是档案性质的数据，有些是在某个机器上产生、在另外一个机器上处理的中间数据。由于这些对大型文件的访问方式，添加操作成为性能优化和原子性保证的焦点。而在客户机中缓存数据块则失去了吸引力。 工作量主要由两种读操作构成：对大量数据的流方式的读操作和对少量数据的随机方式的读操作。在前一种读操作中，可能要读几百KB，通常达 1MB和更多。来自同一个客户的连续操作通常会读文件的一个连续的区域。随机的读操作通常在一个随机的偏移处读几个KB。性能敏感的应用程序通常将对少量数据的读操作进行分类并进行批处理以使得读操作稳定地向前推进，而不要让它来来回回的读。 工作量还包含许多对大量数据进行的、连续的、向文件添加数据的写操作。所写的数据的规模和读相似。一旦写完，文件很少改动。在随机位置对少量数据的写操作也支持，但不必非常高效。 系统必须高效地实现定义完好的大量客户同时向同一个文件的添加操作的语义。 系统接口GFS提供了一个相似地文件系统界面，虽然它没有向POSIX那样实现标准的API。文件在目录中按层次组织起来并由路径名标识。 体系结构一个GFS集群由一个master和大量的chunk server构成，并被许多客户（client）访问。如图1所示。master和chunk server通常是运行用户层服务进程的Linux机器。只要资源和可靠性允许，chunk server和client可以运行在同一个机器上。 文件被分成固定大小的块。每个块由一个不变的、全局唯一的64位的chunk－handle标识，chunk－handle是在块创建时由 master分配的。chunk server将块当作Linux文件存储在本地磁盘并可以读和写由chunk－handle和位区间指定的数据。出于可靠性考虑，每一个块被复制到多个chunk server上。默认情况下，保存3个副本，但这可以由用户指定。 master维护文件系统所以的元数据（metadata），包括名字空间、访问控制信息、从文件到块的映射以及块的当前位置。它也控制系统范围的活动，如块租约（lease）管理，孤儿块的垃圾收集，chunk server间的块迁移。master定期通过HeartBeat消息与每一个chunk server通信，给chunk server传递指令并收集它的状态。 与每个应用相联的GFS客户代码实现了文件系统的API并与master和chunk server通信以代表应用程序读和写数据。客户与master的交换只限于对元数据（metadata）的操作，所有数据方面的通信都直接和chunk server联系。 客户和chunk server都不缓存文件数据。因为用户缓存的益处微乎其微，这是由于数据太多或工作集太大而无法缓存。不缓存数据简化了客户程序和整个系统，因为不必考虑缓存的一致性问题。但用户缓存元数据（metadata）。chunk server也不必缓存文件，因为块时作为本地文件存储的。 单master只有一个master也极大的简化了设计并使得master可以根据全局情况作出先进的块放置和复制决定。但是我们必须要将master对读和写的参与减至最少，这样它才不会成为系统的瓶颈。client从来不会从master读和写文件数据。client只是询问master它应该和哪个 chunk server联系。client在一段限定的时间内将这些信息缓存，在后续的操作中client直接和chunk server交互。 client使用固定的块大小将应用程序指定的文件名和字节偏移转换成文件的一个块索引（chunk index）。 给master发送一个包含文件名和块索引的请求。 master回应对应的chunk handle和副本的位置（多个副本）。 client以文件名和块索引为键缓存这些信息。（handle和副本的位置）。 client 向其中一个副本发送一个请求，很可能是最近的一个副本。请求指定了chunk handle（chunk server以chunk handle标识chunk）和块内的一个字节区间。 除非缓存的信息不再有效（cache for a limited time）或文件被重新打开，否则以后对同一个块的读操作不再需要client和master间的交互。 通常client可以在一个请求中询问多个chunk的地址，而master也可以很快回应这些请求。 块规模块规模是设计中的一个关键参数。我们选择的是64MB，这比一般的文件系统的块规模要大的多。每个块的副本作为一个普通的Linux文件存储，在需要的时候可以扩展。块规模较大的好处有： 减少client和master之间的交互。因为读写同一个块只是要在开始时向master请求块位置信息。对于读写大型文件这种减少尤为重要。即使对于访问少量数据的随机读操作也可以很方便的为一个规模达几个TB的工作集缓缓存块位置信息。 client在一个给定的块上很可能执行多个操作，和一个chunk server保持较长时间的TCP连接可以减少网络负载。 这减少了master上保存的元数据（metadata）的规模，从而使得可以将metadata放在内存中。这又会带来一些别的好处。 不利的一面： 一个小文件可能只包含一个块，如果很多client访问改文件的话，存储这些块的chunk server将成为访问的热点。但在实际应用中，应用程序通常顺序地读包含多个块的文件，所以这不是一个主要问题。 元数据（metadata）master存储了三中类型的metadata：文件的名字空间和块的名字空间，从文件到块的映射，块的副本的位置。所有的metadata都放在内存中。前两种类型的metadata通过向操作日志登记修改而保持不变，操作日志存储在master的本地磁盘并在几个远程机器上留有副本。使用日志使得我们可以很简单地、可靠地更新master的状态，即使在master崩溃的情况下也不会有不一致的问题。相反，mater在每次启动以及当有chunk server加入的时候询问每个chunk server的所拥有的块的情况。 内存数据结构因为metadata存储在内存中，所以master的操作很快。进一步，master可以轻易而且高效地定期在后台扫描它的整个状态。这种定期地扫描被用于实现块垃圾收集、chunk server出现故障时的副本复制、为平衡负载和磁盘空间而进行的块迁移。 这种方法的一个潜在的问题就是块的数量也即整个系统的容量是否受限与master的内存。实际上，这并不是一个严重的问题。master为每个 64MB的块维护的metadata不足64个字节。除了最后一块，文件所有的块都是满的。类似的，每个文件的名字空间数据也不足64个字节，因为文件名是以一种事先确定的压缩方式存储的.如果要支持更大的文件系统，那么增加一些内存的方法对于我们将元数据（metadata）保存在内存种所获得的简单性、可靠性、高性能和灵活性来说，这只是一个很小的代价。 块位置master并不为chunk server所拥有的块的副本的保存一个不变的记录。它在启动时通过简单的查询来获得这些信息。master可以保持这些信息的更新，因为它控制所有块的放置并通过HeartBeat消息来监控chunk server的状态。 这样做的好处：因为chunk server可能加入或离开集群、改变路径名、崩溃、重启等，一个集群重有成百个server，这些事件经常发生，这种方法就排除了master与chunk server之间的同步问题。 另一个原因是：只有chunk server才能确定它自己到底有哪些块，由于错误，chunk server中的一些块可能会很自然的消失，这样在master中就没有必要为此保存一个不变的记录。 操作日志操作日志包含了对metadata所作的修改的历史记录。它作为逻辑时间线定义了并发操作的执行顺序。文件、块以及它们的版本号都由它们被创建时的逻辑时间而唯一地、永久地被标识。 操作日志是如此的重要，我们必须要将它可靠地保存起来，并且只有在metadata的改变固定下来之后才将变化呈现给用户。所以我们将操作日志复制到数个远程的机器上，并且只有在将相应的日志记录写到本地和远程的磁盘上之后才回答用户的请求。 master可以用操作日志来恢复它的文件系统的状态。为了将启动时间减至最小，日志就必须要比较小。每当日志的长度增长到超过一定的规模后，master就要检查它的状态，它可以从本地磁盘装入最近的检查点来恢复状态。 创建一个检查点比较费时，master的内部状态是以一种在创建一个检查点时并不耽误即将到来的修改操作的方式来组织的。master切换到一个新的日子文件并在一个单独的线程中创建检查点。这个新的检查点记录了切换前所有的修改。在一个有数十万文件的集群中用一分钟左右就能完成。创建完后，将它写入本地和远程的磁盘。 数据完整性名字空间的修改必须是原子性的，它们只能有master处理：名字空间锁保证了操作的原子性和正确性，而master的操作日志在全局范围内定义了这些操作的顺序。 文件区间的状态在修改之后依赖于修改的类型，不论操作成功还是失败，也不论是不是并发操作。如果不论从哪个副本上读，所有的客户都看到同样的数据，那么文件的这个区域就是一致的。如果文件的区域是一致的并且用户可以看到修改操作所写的数据，那么它就是已定义的。如果修改是在没有并发写操作的影响下完成的，那么受影响的区域是已定义的，所有的client都能看到写的内容。成功的并发写操作是未定义但却是一致的。失败的修改将使区间处于不一致的状态。 write操作在应用程序指定的偏移处写入数据，而record append操作使得数据（记录）即使在有并发修改操作的情况下也至少原子性的被加到GFS指定的偏移处，偏移地址被返回给用户。 在一系列成功的修改操作后，最后的修改操作保证文件区域是已定义的。GFS通过对所有的副本执行同样顺序的修改操作并且使用块版本号检测过时的副本（由于chunk server退出而导致丢失修改）来做到这一点。 因为用户缓存了会位置信息，所以在更新缓存之前有可能从一个过时的副本中读取数据。但这有缓存的截止时间和文件的重新打开而受到限制。 在修改操作成功后，部件故障仍可以是数据受到破坏。GFS通过master和chunk server间定期的handshake，借助校验和来检测对数据的破坏。一旦检测到，就从一个有效的副本尽快重新存储。只有在GFS检测前，所有的副本都失效，这个块才会丢失。 系统交互租约（lease）和修改顺序数据流我们的目标是充分利用每个机器的网络带宽，避免网络瓶颈和延迟。为了有效的利用网络，我们将数据流和控制流分离。数据是以流水线的方式在选定的chunker server链上线性的传递的。每个机器的整个对外带宽都被用作传递数据。为避免瓶颈，每个机器在收到数据后，将它收到数据尽快传递给离它最近的机器。 原子性的record AppendGFS提供了一个原子性的添加操作：record append。在传统的写操作中，client指定被写数据的偏移位置，向同一个区间的并发的写操作是不连续的：区间有可能包含来自多个client的数据碎片。在record append中， client只是指定数据。GFS在其选定的偏移出将数据至少原子性的加入文件一次，并将偏移返回给client。 在分布式的应用中，不同机器上的许多client可能会同时向一个文件执行添加操作，添加操作被频繁使用。如果用传统的write操作，可能需要额外的、复杂的、开销较大的同步，例如通过分布式锁管理。在我们的工作量中，这些文件通常以多个生产者单个消费者队列的方式或包含从多个不同 client的综合结果。 record append和前面讲的write操作的控制流差不多，只是在primary上多了一些逻辑判断。首先，client将数据发送到文件最后一块的所有副本上。然后向primary发送请求。Primary检查添加操作是否会导致该块超过最大的规模（64M）。如果这样，它将该块扩充到最大规模，并告诉其它副本做同样的事，同时通知client该操作需要在下一个块上重新尝试。如果记录满足最大规模的要求，primary就会将数据添加到它的副本上，并告诉其它的副本在在同样的偏移处写数据，最后primary向client报告写操作成功。如果在任何一个副本上record append操作失败，client将重新尝试该操作。这时候，同一个块的副本可能包含不同的数据，因为有的可能复制了全部的数据，有的可能只复制了部分。GFS不能保证所有的副本每个字节都是一样的。它只保证每个数据作为一个原子单元被写过至少一次。这个是这样得出的：操作要是成功，数据必须在所有的副本上的同样的偏移处被写过。进一步，从这以后，所有的副本至少和记录一样长，所以后续的记录将被指定到更高的偏移处或者一个不同的块上，即使另一个副本成了primary。根据一致性保证，成功的record append操作的区间是已定义的。而受到干扰的区间是不一致的。 快照（snapshot）快照操作几乎在瞬间构造一个文件和目录树的副本，同时将正在进行的其他修改操作对它的影响减至最小。 我们使用copy-on-write技术来实现snapshot。当master受到一个snapshot请求时，它首先将要snapshot的文件上块上的lease。这使得任何一个向这些块写数据的操作都必须和master交互以找到拥有lease的副本。这就给master一个创建这个块的副本的机会。 副本被撤销或终止后，master在磁盘上登记执行的操作，然后复制源文件或目录树的metadata以对它的内存状态实施登记的操作。这个新创建的snapshot文件和源文件（其metadata）指向相同的块（chunk）。 Snapshot之后，客户第一次向chunk c写的时候，它发一个请求给master以找到拥有lease的副本。master注意到chunk c的引用记数比1大，它延迟对用户的响应，选择一个chunk handle C’,然后要求每一有chunk c的副本的chunk server创建一个块C’。每个chunk server在本地创建chunk C’避免了网络开销。从这以后和对别的块的操作没有什么区别。 MASTER操作MASTER执行所有名字空间的操作，除此之外，他还在系统范围管理数据块的复制：决定数据块的放置方案，产生新数据块并将其备份，和其他系统范围的操作协同来确保数据备份的完整性，在所有的数据块服务器之间平衡负载并收回没有使用的存储空间。 名字空间管理和加锁与传统文件系统不同的是，GFS没有与每个目录相关的能列出其所有文件的数据结构，它也不支持别名（unix中的硬连接或符号连接），不管是对文件或是目录。GFS的名字空间逻辑上是从文件元数据到路径名映射的一个查用表。 MASTER在执行某个操作前都要获得一系列锁，例如，它要对/d1/d2…/dn/leaf执行操作，则它必须获得/d1，/d1/d2，…， /d1/d2/…/dn的读锁，/d1/d2…/dn/leaf的读锁或写锁（其中leaf可以使文件也可以是目录）。MASTER操作的并行性和数据的一致性就是通过这些锁来实现的。 备份存储放置策略一个GFS集群文件系统可能是多层分布的。一般情况下是成千上万个文件块服务器分布于不同的机架上，而这些文件块服务器又被分布于不同机架上的客户来访问。因此，不同机架上的两台机器之间的通信可能通过一个或多个交换机。数据块冗余配置策略要达到连个目的：最大的数据可靠性和可用性，最大的网络带宽利用率。因此，如果仅仅把数据的拷贝置于不同的机器上很难满足这两个要求，必须在不同的机架上进行数据备份。这样即使整个机架被毁或是掉线，也能确保数据的正常使用。这也使数据传输，尤其是读数据，可以充分利用带宽，访问到多个机架，而写操作，则不得不涉及到更多的机架。 产生、重复制、重平衡数据块当MASTER产生新的数据块时，如何放置新数据块，要考虑如下几个因素：（1）尽量放置在磁盘利用率低的数据块服务器上，这样，慢慢地各服务器的磁盘利用率就会达到平衡。（2）尽量控制在一个服务器上的“新创建”的次数。（3）由于上一小节讨论的原因，我们需要把数据块放置于不同的机架上。 MASTER在可用的数据块备份低于用户设定的数目时需要进行重复制。这种情况源于多种原因：服务器不可用，数据被破坏，磁盘被破坏，或者备份数目被修改。每个被需要重复制的数据块的优先级根据以下几项确定：第一是现在的数目距目标的距离，对于能阻塞用户程序的数据块，我们也提高它的优先级。最后， MASTER按照产生数据块的原则复制数据块，并把它们放到不同的机架内的服务器上。 MASTER周期性的平衡各服务器上的负载：它检查chunk分布和负载平衡，通过这种方式来填充一个新的服务器而不是把其他的内容统统放置到它上面带来大量的写数据。数据块放置的原则与上面讨论的相同，此外，MASTER还决定那些数据块要被移除，原则上他会清除那些空闲空间低于平均值的那些服务器。 垃圾收集在一个文件被删除之后，GFS并不立即收回磁盘空间，而是等到垃圾收集程序在文件和数据块级的的检查中收回。 当一个文件被应用程序删除之后，MASTER会立即记录下这些变化，但文件所占用的资源却不会被立即收回，而是重新给文件命了一个隐藏的名字，并附上了删除的时间戳。在MASTER定期检查名字空间时，它删除超过三天（可以设定）的隐藏的文件。在此之前，可以以一个新的名字来读文件，还可以以前的名字恢复。当隐藏的文件在名字空间中被删除以后，它在内存中的元数据即被擦除，这就有效地切断了他和所有数据块的联系。 在一个相似的定期的名字空间检查中，MASTER确认孤儿数据块（不属于任何文件）并擦除他的元数据，在和MASTER的心跳信息交换中，每个服务器报告他所拥有的数据块，MASTER返回元数据不在内存的数据块，服务器即可以删除这些数据块。 过时数据的探测在数据更新时如果服务器停机了，那么他所保存的数据备份就会过时。对每个数据块，MASTER设置了一个版本号来区别更新过的数据块和过时的数据块。 当MASTER授权一个新的lease时，他会增加数据块的版本号并会通知更新数据备份。MASTER和备份都会记录下当前的版本号，如果一个备份当时不可用，那么他的版本号不可能提高，当chunk server重新启动并向MASTER报告他的数据块集时，MASTER就会发现过时的数据。 MASTER在定期的垃圾收集程序中清除过时的备份，在此以前，处于效率考虑，在各客户及英大使，他会认为根本不存在过时的数据。作为另一个安全措施， MASTER在给客户及关于数据块的应答或是另外一个读取数据的服务器数据是都会带上版本信息，在操作前客户机和服务器会验证版本信息以确保得到的是最新的数据。 容错和诊断高可靠性快速恢复不管如何终止服务，MASTER和数据块服务器都会在几秒钟内恢复状态和运行。实际上，我们不对正常终止和不正常终止进行区分，服务器进程都会被切断而终止。客户机和其他的服务器会经历一个小小的中断，然后它们的特定请求超时，重新连接重启的服务器，重新请求。 数据块备份如上文所讨论的，每个数据块都会被备份到放到不同机架上的不同服务器上。对不同的名字空间，用户可以设置不同的备份级别。在数据块服务器掉线或是数据被破坏时，MASTER会按照需要来复制数据块。 MASTER备份为确保可靠性，MASTER的状态、操作记录和检查点都在多台机器上进行了备份。一个操作只有在数据块服务器硬盘上刷新并被记录在MASTER和其备份的上之后才算是成功的。如果MASTER或是硬盘失败，系统监视器会发现并通过改变域名启动它的一个备份机，而客户机则仅仅是使用规范的名称来访问，并不会发现MASTER的改变。 数据完整性每个数据块服务器都利用校验和来检验存储数据的完整性。原因：每个服务器随时都有发生崩溃的可能性，并且在两个服务器间比较数据块也是不现实的，同时，在两台服务器间拷贝数据并不能保证数据的一致性。 每个Chunk按64kB的大小分成块，每个块有32位的校验和，校验和和日志存储在一起，和用户数据分开。 在读数据时，服务器首先检查与被读内容相关部分的校验和，因此，服务器不会传播错误的数据。如果所检查的内容和校验和不符，服务器就会给数据请求者返回一个错误的信息，并把这个情况报告给MASTER。客户机就会读其他的服务器来获取数据，而MASTER则会从其他的拷贝来复制数据，等到一个新的拷贝完成时，MASTER就会通知报告错误的服务器删除出错的数据块。 附加写数据时的校验和计算优化了，因为这是主要的写操作。我们只是更新增加部分的校验和，即使末尾部分的校验和数据已被损坏而我们没有检查出来，新的校验和与数据会不相符，这种冲突在下次使用时将会被检查出来。 相反，如果是覆盖现有数据的写，在写以前，我们必须检查第一和最后一个数据块，然后才能执行写操作，最后计算和记录校验和。如果我们在覆盖以前不先检查首位数据块，计算出的校验和则会因为没被覆盖的数据而产生错误。 在空闲时间，服务器会检查不活跃的数据块的校验和，这样可以检查出不经常读的数据的错误。一旦错误被检查出来，服务器会拷贝一个正确的数据块来代替错误的。 诊断工具广泛而细致的诊断日志以微小的代价换取了在问题隔离、诊断、性能分析方面起到了重大的作用。GFS服务器用日志来记录显著的事件（例如服务器停机和启动）和远程的应答。远程日志记录机器之间的请求和应答，通过收集不同机器上的日志记录，并对它们进行分析恢复，我们可以完整地重现活动的场景，并用此来进行错误分析。 测量测试环境一台主控机，两台主控机备份，16台数据块服务器，16台客户机。 每台机器：2块PIII1.4G处理器，2G内存，2块80G5400rpm的硬盘，1块100Mbps全双工网卡 19台服务器连接到一个HP2524交换机上，16台客户机俩接到领外一台交换机上，两台交换机通过1G的链路相连。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[每天一张照片]]></title>
      <url>%2F2017%2F01%2F25%2Feveryday-picture%2F</url>
      <content type="text"><![CDATA[2017-0124th 23rd 22nd 21st 19th 18th 16th 15th 13th 12th 11th 2016-1230th]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[《三体》读后感]]></title>
      <url>%2F2017%2F01%2F16%2Fthree-body%2F</url>
      <content type="text"><![CDATA[人物叶文洁大史罗辑托马斯・维德程心云天明三体人歌者 我毁灭你，与你有何关系 事件叶文洁发射信号给三体人设置面壁者设置执剑人水滴毁灭人类星舰人类星舰黑暗战役三体毁灭太阳系毁灭云天明赠送恒星给程心云天明制造小星球程心归还小星球给宇宙名词黑暗森林]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[对订单系统的一些思考]]></title>
      <url>%2F2017%2F01%2F12%2Forder-system%2F</url>
      <content type="text"><![CDATA[订单是什么 订单是交易的快照信息，用于记录交易发生时的相关信息 订单一般包含哪些信息 用户：商品或服务的消费者 商家：商品或服务的提供者 物品：交易涉及的商品或服务的名称、属性及描述信息 价格：物品的价格，根据需要可以分为原始价格、单位价格、最终价格等 优惠：商家提供给用户的用于减免价格的行为描述，一般包含折扣、代金券、抵扣券等各种类型 时间：一般包含交易发生与结束时间、支付发生与结束时间、物品发货与完成时间等 支付流水号：凡是涉及支付行为的订单，一般都需要与支付流水号相关联，支付流水号一般由其他系统维护，记录支付渠道、账户变更等信息 订单的常见状态与主要流程 创建：用户通过前台售卖页面或API发起下单请求，订单系统根据请求内容创建新的订单，此时订单的状态为“初始化” 支付：若订单最终需要支付的金额不为0，则一般由用户通过前台售卖页面或API发起支付请求，订单系统调用外部支付系统发起支付，若支付请求是同步的，则可根据支付成功与失败决定订单新的状态，若支付请求是异步的，一般需要先将订单状态切换为“支付中”，后续通过订单系统轮询或支付系统回调的方式获取支付结果 发货：已支付的订单或者不需要支付的订单，系统可直接进行发货，发货结果一般由订单系统轮询或外部系统回调进行更新 退款：用户通过前台管理页面或API发起退款请求，一般仅当订单处于“发货完成”或“发货失败”时才可进行退款 查询：用户通过前台售卖页面或API，查询符合条件的单个或多个订单 取消：处于“初始化”状态的订单，一般可由用户主动取消，若订单超过一定时间未支付，系统也可自动取消 删除：对于“已取消”或“已退款”状态的订单，用户可通过前台管理页面或API进行删除，后续查询请求无法获取“已删除”状态的订单 订单系统的安全问题 权限校验：用户任何操作都需要先鉴权，用户仅能操作自己的订单 操作频率限制：系统针对用户特定操作必须有频率限制，若发现异常请求需要能主动拒绝 通用参数校验：对每一个订单相关的通用参数都需要做类型与取值范围的基础校验，同时需要考虑参数与业务逻辑的相关校验 业务参数校验：通常用户购买的商品都会有特定的属性，这些属性必须是合法且有效的，不能信任前台带过来的任何参数 操作日志：用户在何时进行了何种操作，系统都需要记录下来 数据备份：订单数据库需要避免单点问题 订单系统的性能问题订单号的生成 订单server通常需要分布式部署，但订单号必须是全局唯一的，这就要求有特定的算法用于处理订单号的生成规则，一般可以考虑时间戳、随机数、机器ID等因素的组合 读写分离 普通的订单系统一般是读多写少，对于常见的数据库一主多备部署方式，写请求由主库处理，读请求则分散到各个从库处理 缓存 为减轻数据库的压力，可考虑引入缓存，但缓存会增加系统复杂度，重点需要考虑缓存的更新问题 数据大结点 对于to B的订单server，可能10%的用户覆盖了90%的订单，这种情况下订单表分布是极不均匀的，即使命中索引，数据库处理速度仍然不满足要求，这种情况下需要根据使用场景，引入缓存或特殊逻辑处理这些大结点 分布式事务 订单server与数据库一般是独立部署的，不同server之间通过网络调用进行通信，必然会出现各类异常情况，此时可引入分布式事务，解决各个server之间状态不一致的问题，但分布式事务会增加系统复杂度，同时可能导致性能问题，需要根据实际场景做好评估 其他需要考虑的点 接口可重入：订单server对外提供的接口必须是可重入的，网络超时重试是必然会出现的]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[redis变长字符串(simple dynamic strings)学习笔记]]></title>
      <url>%2F2016%2F10%2F31%2Fredis-data-structure-sds%2F</url>
      <content type="text"><![CDATA[主要文件 sds.h sds.c 结构1234567struct sdshdr &#123; int len; // buf已占用长度 int free; // buf可使用长度 char buf[]; // 实际数据&#125;;typedef char *sds; 知识点flexible array member sds结构一般指向sdshdr-&gt;buf，可以通过sds当前地址计算得到sdshdr地址12const sds s;struct sdshdr *hdr = (void*)(s - (sizeof(struct sdssdr))); 接口说明获取buf的已占用长度定义1static inline size_t sdslen(const sds s); 流程 根据sds当前地址获取sdshdr地址，获取len元素的值 获取buf的可使用长度定义1static inline size_t sdsavail(const sds s); 流程 根据sds当前地址获取sdshdr地址，获取free元素的值 创建一个指定长度的sds，支持初始化定义1sds sdsnewlen(const void *init, size_t initlen); 流程 根据传入的长度创建一个变长字符串，总占用空间为sizeof(struct sdshdr)+initlen+1，再根据需要进行初始化，len设置为initlen，free设置为0 创建一个包含空串的sds定义1sds sdsempty(void); 流程 调用sdsnewlen(“”, 0) 根据指定初始化值创建sds定义1sds sdsnew(const char *init); 流程 调用sdsnewlen(init, initlen)，其中initlen为指定初始化值的长度，若初始化值为NULL，则长度为0 复制sds定义1sds sdsdup(const sds s); 流程 调用sdsnewlen(s, sdslen(s)) 释放sds定义1void sdsfree(sds s); 流程 若传入的sds为NULL，则直接返回。否则先找到sdshdr的起始地址，然后释放其对应内存 根据buf的实际长度更新sdshdr的属性定义1void sdsupdatelen(sds s); 流程 根据sds计算得到sdshdr的起始地址，计算buf的实际长度，len与free的值对应调整 清除sds的内容，使其只包含\0定义1void sdsclear(sds s); 流程 根据sds计算得到sdshdr的起始地址，len设置为0，free对应增加len的原长度 对sds的buf进行扩展定义1sds sdsMakeRoomFor(sds s, size_t addlen); 流程 若当前free长度超过扩展长度，则无需操作，否则根据新长度与SDS_MAX_PREALLOC的关系决定扩展后的长度，最后更新sds的free元素 释放sds多余的内存定义1sds sdsRemoveFreeSpace(sds s); 流程 根据sds计算得到sdshdr的起始地址，计算出实际所需内存大小，释放其余的内存，并将free元素置0 计算sds占用的总内存大小定义1size_t sdsAllocSize(sds s); 流程 根据sds计算得到sdshdr的起始地址，总长度=buf指针大小+已占用长度+可使用长度+1 sds buf的右端增加/减少指定长度定义1void sdsIncrLen(sds s, int incr); 流程 若指定长度为正，则free可用长度必须不小于该值。变更buf内容，将新长度的结尾设置为\0，同时更新len与free元素 将sds buf扩展至指定长度，扩展部分设置为\0定义1sds sdsgrowzero(sds s, size_t len); 流程 若当前已占用长度不小于传入的指定长度，则无需操作，否则调用sdsMakeRoomFor扩展长度，并将扩展的部分置为\0，同时更新len与free元素 扩展sds长度并拼接字符串定义1sds sdscatlen(sds s, const void *t, size_t len); 流程 调用sdsMakeRoomFor扩展len长度，将t拼接至结尾，同时更新len与free元素 在sds末尾拼接字符串定义1sds sdscat(sds s, const char *t); 流程 调用return sdscatlen(s, t, strlen(t)) 在sds末尾拼接另一个sds定义1sds sdscatsds(sds s, const sds t); 流程 调用sdscatlen(s, t, sdslen(t)) 拷贝字符串至sds，指定对应长度定义1sds sdscpylen(sds s, const char *t, size_t len); 流程 若sds长度不够，则调用sdsMakeRoomFor扩展它的长度。复制字符串至buf之后，对应更新len与free元素 拷贝字符串至sds定义1sds sdscpy(sds s, const char *t); 流程 调用sdscpylen(s, t, strlen(t)) 从sds两端删除特定字符定义1sds sdstrim(sds s, const char *cset); 流程 从头部和尾部分别遍历sds buf，获取不满足条件的新头部和尾部的位置，将新头部和尾部的字符复制到buf中，并更新len和free元素 指定头部和尾部的位置截取sds定义1sds sdsrange(sds s, int start, int end); 流程 根据指定的头部和尾部的位置，经过部分边界计算，截取得到新的sds 将sds的字母转换为小写形式定义1void sdstolower(sds s); 流程 遍历sds buf，把字母逐个转换为小写形式 将sds的字母转换为大写形式定义1void sdstoupper(sds s); 流程 遍历sds buf，把字母逐个转换为大写形式 比较两个sds的大小定义1int sdscmp(const sds s1, const sds s2); 流程 获取两个sds对应的sdshdr，从而得到各自的长度，使用memcmp逐个字节比较 将字符串分割成多个sds定义1sds *sdssplitlen(const char *s, int len, const char *sep, int seplen, int *count); 流程 从头至尾扫描sds buf，根据分割串，生成多个对应的sds 释放分隔得到的sds定义1void sdsfreesplitres(sds *tokens, int count); 流程 对tokens指向的sds逐个调用sdsfree释放空间 将long long型整数转换为对应的sds定义1sds sdsfromlonglong(long long value); 流程 使用长度为32的字符串，从value低位至高位逐个获取对应的10进制数字，转换成对应字符存入其中，若value为负，则对应增加负号，最后调用sdsnewlen根据该字符串有效位生成sds 在sds后面拼接repr转换之后的字符串定义1sds sdscatrepr(sds s, const char *p, size_t len); 流程 在sds之后拼接一个双引号，之后按指定长度和字符串进行repr转换和拼接，最后再拼接一个双引号 判断字符是否为16进制相关字符定义1int is_hex_digit(char c); 流程 判断字符是否为0~9或a~f或A~F 将16进制相关字符转换为对应整数值定义1int hex_digit_to_int(char c); 流程 将0~9字符分别转为数字0~9，将a~f或A~F对应转为数字10~15 将命令行参数转换成多个sds定义1sds *sdssplitargs(const char *line, int *argc); 流程 逐个遍历line指向的命令行参数字符串，根据字符串分隔符，同时考虑特殊字符与16进制等情形，得到多个sds 释放命令行参数转换之后得到的sds对应的空间定义1void sdssplitargs_free(sds *argv, int argc); 流程 遍历传入的sds，逐个调用sdsfree释放空间 将sds的字符根据规则替换为别的字符定义1sds sdsmapchars(sds s, const char *from, const char *to, size_t setlen); 流程 遍历sds buf的每个字符，若该字符在集合from中，则对应转换为集合to中的字符 将sds与参数列表按指定格式生成的字符串拼接定义1sds sdscatvprintf(sds s, const char *fmt, va_list ap); 流程 以16为起始长度，根据实际容纳参数列表生成的字符串所需要的长度不断翻倍，最后将调用sdscat进行拼接 将sds与变长参数按指定格式生成的字符串拼接定义1sds sdscatprintf(sds s, const char *fmt, ...); 流程 将变长参数转换为va_list格式，调用sdscatvprintf进行拼接]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[PHP轻量框架分享]]></title>
      <url>%2F2016%2F10%2F11%2Fphp-lightweight-framework%2F</url>
      <content type="text"><![CDATA[背景说明 近期需要将之前功能较复杂的后台服务模块拆成小模块，该模块采用了前人开发的基于MVC的php自研框架，框架本身集成了较多功能，包括接口参数统一校验、异构数据库接口抽象封装等 由于历史悠久且缺乏文档说明，随着需求与版本迭代，代码结构变得比较混乱，维护成本随之增加 由于框架本身的设计限制，无法支持新版本PHP（如5.6）的部分特性，引入一些新的概念与技术变得困难 新模块功能相对比较简单，不需要集成较多特性 框架介绍主要特性 协议可定制（推荐json） 引入ORM，不需要自己封装DB基础操作 配置文件使用YAML格式，可读性较高 适合搭建后台简单服务 方便与常见web server集成（推荐nginx） 框架结构1234567891011121314151617181920212223242526272829303132333435363738common # 公共目录 |- Constants.php # 常量 |- Errors.php # 错误码与错误信息 |- ...configs # 配置目录 |- db.yaml # 数据库配置 |- log.yaml # 日志配置 |- ...models # 模型目录 |- ...services # 服务目录 |- ...controllers # 控制器目录 |- ...libraries # 库目录 |- Configuration.php # 配置解析类 |- HttpRequest.php # HTTP处理类 |- DbConnection.php # DB处理类 |- Log.php # 日志处理类 |- ...logs # 日志目录 |- ...scripts # 离线脚本目录 |- ...tests # 测试目录 |- controllers # 控制器测试目录 |- ... |- services # 服务测试目录 |- ... |- models # 模型测试目录 |- ... |- ...vendor # 包管理目录 |- ...composer.lock # composer锁文件composer.json # composer配置文件phpunit.xml # PHP单元测试配置文件index.php # 请求入口类 目录与文件说明 index.php: 请求入口文件，负责解析请求包，选择合适接口处理请求，组装返回包 common: 存放项目公共文件，如常量、错误码与错误信息等 configs: 存放项目配置文件，如数据库配置、日志配置、业务配置等 models: 每个数据表对应一个文件，每个文件封装了对应数据表的ORM操作（依赖illuminate/database包） services: 每一类服务对应一个文件，每个文件封装了针对一个或多个ORM的操作，需要在这一层处理事务 controllers: 存放接口文件，每个文件对应一个外部调用接口，需要在这一层做好接口参数校验 libraries: 存放项目库文件，如日志操作、数据库操作、配置解析等 scriptes: 存放所有离线脚本 tests: 存放所有测试类 phpunit.xml: 单元测试配置文件，用于执行tests目录下的测试类 logs: 存放所有日志文件 vendor: 存放所有项目依赖的包 composer.json: 包管理配置文件 composer.lock: 包管理操作锁 示例项目 商品库存管理模块]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[异步任务管理模块设计分享]]></title>
      <url>%2F2016%2F10%2F09%2Fasync-task-manage-module%2F</url>
      <content type="text"><![CDATA[构建模块的背景业务发展 业务刚推出的时候，产品考虑的是如何让用户使用我们的资源，因此只要提供针对资源的基本操作（购买、续费、升级等）即可 随着互联网的发展与业务发展，用户对于资源的需求量增加，因此出现了同时购买大批量的资源，同时操作大批量资源的情况，由于响应时间较长，用户体验非常不好 业务搞活动的时候，可能出现较多客户同时购买资源的情况，对正常服务造成影响，用户体验同样较差 后台服务演进 大部分后台服务提供的接口在设计之初，主要考虑的是如何完成业务功能，对于接口性能与操作逻辑优化考虑的相对比较少 业务逻辑变更或发展，导致接口逻辑愈发复杂，模块间的网络调用次数增加，同时后台存储的数据量也逐渐增加，接口耗时随之增加 先针对单个资源的操作接口逐渐洐生出批量操作接口，以应对用户的批量操作请求 大多数批量接口实际是伪批量，后台实际逻辑基本是串行的 常规的接口性能优化，包括数据缓存、逻辑优化、网络调用采用并发处理等，虽然能在一定程度上减少接口耗时，但部分优化使得接口逻辑反而变复杂了，同时部分接口耗时依然达不到要求，随着批量处理的数量的增加，接口性能优化带来的收益愈发不明显 业务搞活动时，接口请求量暴涨，部分耗时接口的性能问题会被放大，严重时可能会耗尽服务器资源，影响正常业务流程 请求异步化的思路什么是请求异步化 后台服务收到请求之后，不立即处理请求，而是把请求记录下来 后台服务跟调用方约定获取请求执行结果的方式 后台服务异步执行对应的请求，并记录执行结果 调用方通过轮询或其他方式获取执行结果 为什么需要异步化 网络调用需要做超时处理，调用方不可能无限期等待后台服务的响应，同时用户体验不好，异步可以使调用方即时获得响应，对此做出相应的用户提示与交互 异步执行请求的频率可以调整，对于活动时接口请求量暴涨的情形，可以降低请求的执行频率，保证主线业务正常运行 为接口性能优化带来一种新的方式，不再需要牺牲代码可维护性与扩展性来做性能优化 请求异步化会带来什么问题 调用方逻辑需要改变，原来的直接请求响应的方式需要变更为轮询的方式，若调用方较多，改造成本会相对较高 需要额外的逻辑与存储来处理对应的异步请求与响应 可能引入外部模块，系统架构复杂度上升 异步任务管理模块的引入为什么需要做独立的模块 后台服务涉及的模块比较多，在微服务比较盛行的今天，每一类相对独立的功能都可能被封装为一个服务模块，每个模块各自实现自己的异步任务管理逻辑，改造成本较高，同时也不好维护 独立的模块可以抽象出异步任务相关的API，规范任务的处理流程，对各个调用方保持统一 模块的几种设计思路子进程同步处理+脚本触发任务检查 主要流程 后台服务模块每次收到请求直接，就把请求对应处理之后，调用异步任务管理模块创建任务的接口 异步任务管理模块收到创建请求，生成任务唯一标识，把请求信息写入存储，同时fork子进程回调后台服务处理对应请求，主进程则直接返回任务标识给后台服务模块，后台服务对应将任务标识返回给调用方 子进程同步等待后台服务的处理结果，并将结果记录到存储中 调用方根据任务标识，不断从异步任务管理模块轮询处理结果 离线脚本主要用于触发任务检查，防止部分任务由于子进程创建失败或者其他原因未处理 特点 请求处理及时，正常情况下可保证每个请求创建之后立即被处理 无法限流，若同时产生的任务较多，可能导致异步任务管理模块所在机器资源不足，或者后台服务压力较大 后台服务处理接口需要支持可重入，防止因为网络等原因导致状态不同步 脚本定时处理任务 主要流程 后台服务模块每次收到请求直接，就把请求对应处理之后，调用异步任务管理模块创建任务的接口 异步任务管理模块收到创建请求，生成任务唯一标识，把请求信息写入存储之后直接返回该标识给后台服务模块，后台服务对应返回给调用方 离线脚本触发异步任务管理模块进行任务处理，异步任务管理模块调用后台服务模块同步获取处理结果，并更新到存储中 调用方根据任务标识，不断从异步任务管理模块轮询处理结果 特点 请求处理有一定延时，若任务较多可能导致任务堆积 可以部署多个离线脚本，但是异步任务管理模块自身负载会对应上升 可以限流，比如离线脚本多久执行一次，限制每次处理多少个任务等 后台服务处理接口需要支持可重入，防止因为网络等原因导致状态不同步 消息队列+脚本触发任务检查 主要流程 后台服务模块每次收到请求直接，就把请求对应处理之后，调用异步任务管理模块创建任务的接口 异步任务管理模块收到创建请求，生成任务唯一标识，把请求信息写入存储之后，添加一条消息到消息队列，然后返回任务标识给后台服务模块，后台服务对应返回给调用方 消息队列根据预配置的策略将消息推送至后台服务模块（此处仅考虑推送模式），后台服务模块收到消息之后对应进行处理，然后将处理结果更新至异步任务管理模块 调用方根据任务标识，不断从异步任务管理模块轮询处理结果 离线脚本主要用于触发任务检查，防止部分任务消息添加失败或者其他原因未处理 特点 引入消息队列，后台服务需要在消息队列配置对应策略与接口 请求处理有一定延时，取决于消息队列推送策略 任务堆积的问题理论上可以通过配置合理的消息队列推送策略解决 限流可以通过消息队列推送策略实现 若消息队列与后台服务通信出现问题，异步任务管理模块无法及时感知，可能需要增加对账机制 后台服务处理接口需要支持可重入，防止因为网络等原因导致状态不同步]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[linux系统调用列表]]></title>
      <url>%2F2016%2F09%2F28%2Flinux-system-call%2F</url>
      <content type="text"><![CDATA[进程控制 系统调用名称 功能描述 fork 创建一个新进程 clone 按指定条件创建子进程 execve 运行可执行文件 exit 中止进程 _exit 立即中止当前进程 getdtablesize 进程所能打开的最大文件数 getpgid 获取指定进程组标识号 setpgid 设置指定进程组标志号 getpgrp 获取当前进程组标识号 setpgrp 设置当前进程组标志号 getpid 获取进程标识号 getppid 获取父进程标识号 getpriority 获取调度优先级 setpriority 设置调度优先级 modify_ldt 读写进程的本地描述表 nanosleep 使进程睡眠指定的时间 nice 改变分时进程的优先级 pause 挂起进程，等待信号 personality 设置进程运行域 prctl 对进程进行特定操作 ptrace 进程跟踪 sched_get_priority_max 取得静态优先级的上限 sched_get_priority_min 取得静态优先级的下限 sched_getparam 取得进程的调度参数 sched_getscheduler 取得指定进程的调度策略 sched_rr_get_interval 取得按RR算法调度的实时进程的时间片长度 sched_setparam 设置进程的调度参数 sched_setscheduler 设置指定进程的调度策略和参数 sched_yield 进程主动让出处理器,并将自己等候调度队列队尾 vfork 创建一个子进程，以供执行新程序，常与execve等同时使用 wait 等待子进程终止 wait3 参见wait waitpid 等待指定子进程终止 wait4 参见waitpid capget 获取进程权限 capset 设置进程权限 getsid 获取会晤标识号 setsid 设置会晤标识号 文件系统控制文件读写操作 系统调用名称 功能描述 fcntl 文件控制 open 打开文件 creat 创建新文件 close 关闭文件描述字 read 读文件 write 写文件 readv 从文件读入数据到缓冲数组中 writev 将缓冲数组里的数据写入文件 pread 对文件随机读 pwrite 对文件随机写 lseek 移动文件指针 _llseek 在64位地址空间里移动文件指针 dup 复制已打开的文件描述字 dup2 按指定条件复制文件描述字 flock 文件加/解锁 poll I/O多路转换 truncate 截断文件 ftruncate 参见truncate umask 设置文件权限掩码 fsync 把文件在内存中的部分写回磁盘 文件系统操作 系统调用名称 功能描述 access 确定文件的可存取性 chdir 改变当前工作目录 fchdir 参见chdir chmod 改变文件方式 fchmod 参见chmod chown 改变文件的属主或用户组 fchown 参见chown lchown 参见chown chroot 改变根目录 stat 取文件状态信息 lstat 参见stat fstat 参见stat statfs 取文件系统信息 fstatfs 参见statfs readdir 读取目录项 getdents 读取目录项 mkdir 创建目录 mknod 创建索引节点 rmdir 删除目录 rename 文件改名 link 创建链接 symlink 创建符号链接 unlink 删除链接 readlink 读符号链接的值 mount 安装文件系统 umount 卸下文件系统 ustat 取文件系统信息 utime 改变文件的访问修改时间 utimes 参见utime quotactl 控制磁盘配额 系统控制 系统调用名称 功能描述 ioctl I/O总控制函数 _sysctl 读/写系统参数 acct 启用或禁止进程记账 getrlimit 获取系统资源上限 setrlimit 设置系统资源上限 getrusage 获取系统资源使用情况 uselib 选择要使用的二进制函数库 ioperm 设置端口I/O权限 iopl 改变进程I/O权限级别 outb 低级端口操作 reboot 重新启动 swapon 打开交换文件和设备 swapoff 关闭交换文件和设备 bdflush 控制bdflush守护进程 sysfs 取核心支持的文件系统类型 sysinfo 取得系统信息 adjtimex 调整系统时钟 alarm 设置进程的闹钟 getitimer 获取计时器值 setitimer 设置计时器值 gettimeofday 取时间和时区 settimeofday 设置时间和时区 stime 设置系统日期和时间 time 取得系统时间 times 取进程运行时间 uname 获取当前UNIX系统的名称、版本和主机等信息 vhangup 挂起当前终端 nfsservctl 对NFS守护进程进行控制 vm86 进入模拟8086模式 create_module 创建可装载的模块项 delete_module 删除可装载的模块项 init_module 初始化模块 query_module 查询模块信息 *get_kernel_syms 取得核心符号,已被query_module代替 内存管理 系统调用名称 功能描述 brk 改变数据段空间的分配 sbrk 参见brk mlock 内存页面加锁 munlock 内存页面解锁 mlockall 调用进程所有内存页面加锁 munlockall 调用进程所有内存页面解锁 mmap 映射虚拟内存页 munmap 去除内存页映射 mremap 重新映射虚拟内存地址 msync 将映射内存中的数据写回磁盘 mprotect 设置内存映像保护 getpagesize 获取页面大小 sync 将内存缓冲区数据写回硬盘 cacheflush 将指定缓冲区中的内容写回磁盘 网络管理 系统调用名称 功能描述 getdomainname 取域名 setdomainname 设置域名 gethostid 获取主机标识号 sethostid 设置主机标识号 gethostname 获取本主机名称 sethostname 设置主机名称 socket控制 系统调用名称 功能描述 socketcall socket系统调用 socket 建立socket bind 绑定socket到端口 connect 连接远程主机 accept 响应socket连接请求 send 通过socket发送信息 sendto 发送UDP信息 sendmsg 参见send recv 通过socket接收信息 recvfrom 接收UDP信息 recvmsg 参见recv listen 监听socket端口 select 对多路同步I/O进行轮询 shutdown 关闭socket上的连接 getsockname 取得本地socket名字 getpeername 获取通信对方的socket名字 getsockopt 取端口设置 setsockopt 设置端口参数 sendfile 在文件或端口间传输数据 socketpair 创建一对已联接的无名socket 用户管理 系统调用名称 功能描述 getuid 获取用户标识号 setuid 设置用户标志号 getgid 获取组标识号 setgid 设置组标志号 getegid 获取有效组标识号 setegid 设置有效组标识号 geteuid 获取有效用户标识号 seteuid 设置有效用户标识号 setregid 分别设置真实和有效的的组标识号 setreuid 分别设置真实和有效的用户标识号 getresgid 分别获取真实的,有效的和保存过的组标识号 setresgid 分别设置真实的,有效的和保存过的组标识号 getresuid 分别获取真实的,有效的和保存过的用户标识号 setresuid 分别设置真实的,有效的和保存过的用户标识号 setfsgid 设置文件系统检查时使用的组标识号 setfsuid 设置文件系统检查时使用的用户标识号 getgroups 获取后补组标志清单 setgroups 设置后补组标志清单 进程间通信 系统调用名称 功能描述 ipc 进程间通信总控制调用 信号 系统调用名称 功能描述 sigaction 设置对指定信号的处理方法 sigprocmask 根据参数对信号集中的信号执行阻塞/解除阻塞等操作 sigpending 为指定的被阻塞信号设置队列 sigsuspend 挂起进程等待特定信号 signal 参见signal kill 向进程或进程组发信号 *sigblock 向被阻塞信号掩码中添加信号,已被sigprocmask代替 *siggetmask 取得现有阻塞信号掩码,已被sigprocmask代替 *sigsetmask 用给定信号掩码替换现有阻塞信号掩码,已被sigprocmask代替 *sigmask 将给定的信号转化为掩码,已被sigprocmask代替 *sigpause 作用同sigsuspend,已被sigsuspend代替 sigvec 为兼容BSD而设的信号处理函数,作用类似sigaction ssetmask ANSI C的信号处理函数,作用类似sigaction 消息 系统调用名称 功能描述 msgctl 消息控制操作 msgget 获取消息队列 msgsnd 发消息 msgrcv 取消息 管道 系统调用名称 功能描述 pipe 创建管道 信号量 系统调用名称 功能描述 semctl 信号量控制 semget 获取一组信号量 semop 信号量操作 共享内存 系统调用名称 功能描述 shmctl 控制共享内存 shmget 获取共享内存 shmat 连接共享内存 shmdt 拆卸共享内存]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[skiplist跳跃表]]></title>
      <url>%2F2016%2F06%2F14%2Fskiplist%2F</url>
      <content type="text"><![CDATA[基本情况 对于有序链表，查找、插入、删除的时间复杂度皆为O(n)，不适用于频繁的上述操作 其他适合于上述操作的数据结构各有优劣，比如平衡二叉查找树，比较花费空间，但查询效率可以保证 跳跃表实现比较简单，结合随机特性，可以保证查找、插入与删除的操作的平均时间复杂度低于O(n) 跳跃表的结点 每个结点包含键(key)与值(value) 每个结点可包含多个指向其他结点的指针，至少包含一个，至多包含n个，n为跳跃表的最大层数 跳跃表的结构 除了普通结点之外，还包含头结点和尾结点，并且跳跃表的总层数为n 每一层都包含头尾结点 如果结点位于第k层，那么它必定位于第k-1层，第k-1层的结点数必定不少于第k层 每个结点均位于第1层，后面每一层的结点数越来越少，但是除了首尾结点之外，其他结点必定保持有序 跳跃表包含随机性，随机性指的是每个结点所在的层数是在它被加入跳跃表时随机生成的，这个特性可用于保证各个操作的平均时间复杂度低于O(n) 跳跃表主要操作及复杂度分析插入操作过程描述 设置当前结点为头结点，当前层数为第n层 随机生成一个整数k，满足1&lt;=k&lt;=n，表示即将插入的结点所在的总层数 对比要插入的key与当前结点的下一结点的key（指当前的层的下一个结点，下同），如果比下一结点的key小，则转步骤4，如果比下一结点的key大，则转步骤5，如果等于下一结点的key，说明该key已存在，直接替换下一结点的value并结束本次操作 接步骤3，说明要插入的位置必定在当前结点与下一结点之间，如果k大于等于当前层数，则记录当前结点，最后插入新结点的时候需要用到该信息，如果当前层数不是第1层，那么当前层数减1，返回步骤3继续，否则转步骤6 接步骤3，说明要插入的位置必定在下一结点之后，因此将当前结点指向下一结点，返回步骤3继续 将当前结点加入第1-k层，每一层插入的位置已在步骤4中记录，操作结束 复杂度分析 最坏情况下，每一层都包含所有结点，那么如果要插入的位置是尾结点之前，则时间复杂度是O(n) 由于每个点的层数的随机性，假设完全随机分布，那么大致可以这样理解：第1层包含n个结点，每个结点有50%的概率出现在第2层，则第2层可能的结点数是n/2，第n层可能的结点数是第n-1层的一半 查找位置的过程中，层数越大，则每次比较之后跳过的结点数越多，平均下来看，最终执行插入操作之前遍历的结点数肯定小于总的结点数，而插入结点所需要变动指针的层数k的期望值是n/2，因此总的复杂度必定低于O(n) 查找操作过程描述 设置当前结点为头结点，当前层数为第n层 对比要查找的key与当前结点的下一结点的key，如果比下一结点的key小，则转步骤4，如果比下一结点的key大，则转步骤4，如果等于下一结点的key，直接返回下一结点的value并结束本次操作 接步骤2，说明要查找的key的位置必定在当前结点与下一结点之间，如果当前层数不是第1层，那么当前层数减1，返回步骤3继续，否则说明该key不存在跳跃表中，返回对应信息 接步骤2，说明要查找的key的位置必定在下一结点之后，因此将当前结点指向下一结点，返回步骤2继续 复杂度分析 查找过程的操作与插入过程类似，只是不需要变更跳跃表的结点指针，因此其复杂度一样低于O(n) 删除操作过程描述 设置当前结点为头结点，当前层数为第n层 对比要插入的key与当前结点的下一结点的key，如果比下一结点的key小，则转步骤3，如果比下一结点的key大，则转步骤4，如果等于下一结点的key，则将当前结点在本层的指针指向下一结点的下一结点 接步骤2，说明要删除的位置必定在当前结点与下一结点之间，如果当前层数不是第1层，那么当前层数减1，返回步骤2继续，否则结束本次操作 接步骤2，说明要删除的位置必定在下一结点之后，因此将当前结点指向下一结点，返回步骤2继续 如果需要手动释放结点占用的空间或返回被删除的结点的value，则需要在步骤2记录对应的结点，并在遍历结束之后删除它 复杂度分析 删除过程与插入过程类似，只是把对应的指针操作相反，其复杂度一样低于O(n) 跳跃表的python实现结点类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768&quot;&quot;&quot;结点类&quot;&quot;&quot;class Node(object): # 构造函数 def __init__(self, key, value): if type(key) != KEY_TYPE: raise TypeError self.key = key self.value = value self.forwardNodes = &#123;&#125; self.numForward = 0 # 设置某一层的前向结点 def setForwardNode(self, level, node): if not isinstance(node, Node): raise TypeError if type(level) != int: raise TypeError if level &lt; 0: raise ValueError self.forwardNodes[level] = node self.numForward = len(self.forwardNodes) # 获取某一层的前向结点 def getForwardNode(self, level): if type(level) != int: raise TypeError if level &lt; 0: raise ValueError if level not in self.forwardNodes.keys(): raise KeyError return self.forwardNodes[level] # 打印结点信息 def dump(self): print(&apos;key: %s&apos; % str(self.key)) print(&apos;value: %s&apos; % str(self.value)) print(&apos;forward nodes: %s&apos; % str(self.forwardNodes)) print(&apos;num forward: %s&apos; % str(self.numForward)) # 获取前向结点数 def numForward(self): return self.numForward # 获取结点的键 def getKey(self): return self.key # 获取结点的值 def getValue(self): return self.value # 设置结点的值 def setValue(self, value): self.value = value 跳跃表类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148&quot;&quot;&quot;跳跃表类&quot;&quot;&quot;class SkipList(object): # 构造函数 def __init__(self, level = MAX_LEVEL): if type(level) != int: print(type(level)) raise TypeError if level &lt; 1: raise ValueError self.level = int(level) self.nil = Node(-1, -1) self.head = Node(0, 0) for i in xrange(self.level): self.head.setForwardNode(i + 1, self.nil) # 插入结点时获取随机层数 def genRandomLevel(self): return random.randint(1, self.level) # 插入新的结点 def insert(self, key, value): node = Node(key, value) tmpLevel = self.genRandomLevel() tmpNode = self.head backwardNodes = &#123;&#125; while tmpLevel &gt;= 1: forwardNode = tmpNode.getForwardNode(tmpLevel) if forwardNode == self.nil: backwardNodes[tmpLevel] = tmpNode tmpLevel -= 1 continue if forwardNode.getKey() &lt; key: tmpNode = forwardNode continue elif forwardNode.getKey() &gt; key: backwardNodes[tmpLevel] = tmpNode tmpLevel -= 1 continue # 键已存在，直接替换结点的值即可 forwardNode.setValue(value) return for level in backwardNodes.keys(): node.setForwardNode(level, backwardNodes[level].getForwardNode(level)) backwardNodes[level].setForwardNode(level, node) # 搜索某个键对应的值 def search(self, key): if type(key) != KEY_TYPE: raise TypeError tmpLevel = self.level tmpNode = self.head while tmpLevel &gt;= 1: forwardNode = tmpNode.getForwardNode(tmpLevel) if forwardNode == self.nil: tmpLevel -= 1 continue if forwardNode.getKey() &lt; key: tmpNode = forwardNode continue elif forwardNode.getKey() &gt; key: tmpLevel -= 1 continue # 找到对应结点则直接返回它的值 return forwardNode.getValue() # 找不到对应结点，返回None return None # 删除键对应的结点 def delete(self, key): if type(key) != KEY_TYPE: raise TypeError tmpLevel = self.level tmpNode = self.head node = None while tmpLevel &gt;= 1: forwardNode = tmpNode.getForwardNode(tmpLevel) if forwardNode == self.nil: tmpLevel -= 1 continue if forwardNode.getKey() &lt; key: tmpNode = forwardNode continue elif forwardNode.getKey() &gt; key: tmpLevel -= 1 continue # 结点在某一层存在指针，调整该层的指针 tmpNode.setForwardNode(tmpLevel, forwardNode.getForwardNode(tmpLevel)) node = forwardNode value = forwardNode.getValue() # 键对应的结点存在，则删除之，并返回它的值 if node is not None: value = node.getValue() del(node) return value # 找不到对应的结点，抛出异常 raise KeyError # 打印跳跃表 def dump(self): tmpLevel = self.level tmpNode = self.head line = &apos;&apos; while tmpLevel &gt;= 1: forwardNode = tmpNode.getForwardNode(tmpLevel) if forwardNode != self.nil: line += &apos;(%s, %s) -&gt; &apos; % (forwardNode.getKey(), forwardNode.getValue()) tmpNode = forwardNode continue print(&apos;level %d: (head) -&gt; %s (tail)&apos; % (tmpLevel, line)) tmpNode = self.head tmpLevel -= 1 line = &apos;&apos; 简单测试类12345678910111213141516if __name__ == &apos;__main__&apos;: skipList = SkipList() keys = list(range(0, 10)) for key in keys: skipList.insert(key, key) for key in keys: skipList.insert(key, key) skipList.dump() print(&quot;delete 3:&quot;, skipList.delete(3)) skipList.dump() print(&quot;delete 8:&quot;, skipList.delete(8)) skipList.dump() keys = list(range(0, 11)) for key in keys: print(&apos;search key %d&apos; % key) print(skipList.search(key))]]></content>
    </entry>

    
  
  
</search>
